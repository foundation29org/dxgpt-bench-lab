# Comparaci√≥n GPT-5.2: Reasoning Effort (Low vs Medium vs High)

## Resumen Ejecutivo

Comparaci√≥n de resultados de `gpt-5.2` con diferentes niveles de `reasoning_effort` en el dataset `all_150` con prompt `juanjo_classic_v2`.

## Resultados Globales

| M√©trica | Low | Medium | High |
|---------|-----|--------|------|
| **Total casos** | 150 | 150 | 150 |
| **Casos matched** | 150 | 149 | 137 |
| **Casos unmatched** | 0 | 1 | **13** |
| **Success rate** | **100.0%** | 99.33% | **91.33%** |
| **Average position** | 1.727 | 1.664 | 1.781 |
| **P1 (posici√≥n 1)** | 100 | 98 | 88 |
| **P2 (posici√≥n 2)** | 25 | 22 | 21 |
| **P3 (posici√≥n 3)** | 8 | 19 | 15 |

## An√°lisis Detallado

### üü¢ Low Reasoning Effort
- **Mejor resultado**: 100% de √©xito
- **Mejor posici√≥n promedio**: 1.727
- **M√°s casos en P1**: 100 casos
- **Sin casos rechazados**

### üü° Medium Reasoning Effort
- **Buen resultado**: 99.33% de √©xito
- **Mejor posici√≥n promedio**: 1.664 (mejor de los tres)
- **Solo 1 caso rechazado**
- **M√°s casos en P3**: 19 casos (posiblemente m√°s conservador)

### üî¥ High Reasoning Effort
- **Peor resultado**: 91.33% de √©xito
- **13 casos rechazados** (8.67% del total)
- **Peor posici√≥n promedio**: 1.781 (incluso en casos exitosos)
- **Menos casos en P1**: 88 casos (64.2% vs 66.7% en low, 65.8% en medium)
- **M√°s casos en posiciones peores**: P4 (5), P5 (4), P6 (2), P7 (1), P10 (1)

## M√©todos de Resoluci√≥n

### Low
- SNOMED: 59 casos
- ICD10_EXACT: 16 casos
- ICD10_SIBLING: 8 casos
- LLM_JUDGMENT: 62 casos
- BERT_AUTOCONFIRM: 1 caso
- BERT_MATCH: 3 casos
- ICD10_PARENT: 1 caso

### Medium
- SNOMED: 59 casos
- ICD10_EXACT: 14 casos
- ICD10_SIBLING: 10 casos
- LLM_JUDGMENT: 59 casos
- BERT_AUTOCONFIRM: 1 caso
- BERT_MATCH: 3 casos
- ICD10_PARENT: 3 casos

### High
- SNOMED: 56 casos (-3 vs low/medium)
- ICD10_EXACT: 8 casos (-8 vs low, -6 vs medium)
- ICD10_SIBLING: 9 casos
- LLM_JUDGMENT: 59 casos
- BERT_AUTOCONFIRM: 2 casos
- BERT_MATCH: 2 casos
- ICD10_PARENT: 1 caso

## Problemas Identificados con High Reasoning Effort

### 1. **Respuestas Vac√≠as por L√≠mite de Tokens de Reasoning** ‚ö†Ô∏è CR√çTICO
- **13 casos fallaron** con respuestas vac√≠as: `[EMPTY_RESPONSE] GPT-5 returned empty content`
- **Causa ra√≠z**: Con `reasoning_effort: high`, GPT-5 usa **todos los 12,000 tokens de reasoning** y no genera contenido en la respuesta final
- **Ejemplo del log**:
  ```
  TOKENS: prompt=518, completion=12000 (reasoning=12000, response=0), total=12518, finish_reason=length
  RAW_RESPONSE: [EMPTY_RESPONSE] GPT-5 returned empty content - check prompt format
  ```
- **Casos afectados**: R664, R955, R601, R457, R316, R542, R213, S9, R206, R549, R633, R959, R132
- **Problema**: El modelo dedica tanto tiempo a "razonar internamente" que se queda sin tokens para generar la respuesta final

### 2. **Cambio en el Orden de Probabilidad** üîÑ
- **Problema real**: Con `high` reasoning effort, el modelo **cambia el orden** de los diagn√≥sticos, colocando diagn√≥sticos correctos pero m√°s espec√≠ficos en **posiciones peores**
- **Tu observaci√≥n es correcta**: Ser m√°s espec√≠fico NO es malo si el diagn√≥stico es correcto. El problema es que el **sistema de evaluaci√≥n premia la posici√≥n**, no la especificidad.
- **Ejemplos reales**:
  - **Caso 7 (Sarcoidosis)**:
    - Low: "Sarcoidosis" en **P3** 
    - Medium: "Sarcoidosis" en **P4**
    - High: "Sarcoidosis (systemic granulomatous disease)" en **P3** (similar a low)
  - **Caso 8 (Rett syndrome)**:
    - Low: "Rett syndrome (MECP2-related)" en **P2**
    - Medium: "Rett syndrome (MECP2-related)" en **P3**
    - High: "Rett syndrome (MECP2-related)" en **P3** (similar a medium)
  - **Caso 18 (Glutaric acidemia)**:
    - Low: "Glutaric acidemia type I" en **P7** ‚ùå
    - Medium: "Glutaric acidemia type I" en **P6** ‚ùå
    - High: "Glutaric acidemia type I (glutaryl-CoA dehydrogenase deficiency)" en **P2** ‚úÖ (MEJOR que low/medium)
- **Conclusi√≥n importante**:
  1. **El diagn√≥stico m√°s espec√≠fico puede ser correcto** y cl√≠nicamente mejor
  2. **PERO el sistema de evaluaci√≥n busca coincidencias por c√≥digos SNOMED/ICD-10** en orden secuencial (P1, P2, P3...)
  3. **Si el diagn√≥stico correcto est√° en P2 o P3 en lugar de P1**, empeora la posici√≥n promedio
  4. **El razonamiento excesivo** puede hacer que el modelo sobre-piense y cambie el orden de probabilidad, colocando diagn√≥sticos correctos pero m√°s espec√≠ficos despu√©s de otros que considera m√°s probables
  5. **Resultado**: Aunque los diagn√≥sticos sean correctos y m√°s espec√≠ficos, est√°n en posiciones peores en promedio (1.781 vs 1.664 en medium)

### 3. Evaluaci√≥n de m√∫ltiples GDX
- Cuando un caso tiene m√∫ltiples GDX, el evaluador eval√∫a cada GDX individualmente
- Si un GDX espec√≠fico no coincide con ning√∫n DDX, se marca como rechazado
- Esto puede explicar algunos de los rechazos cuando hay m√∫ltiples GDX en un caso

### 4. Errores de Parsing
- Algunos casos tienen errores de parsing JSON: `Expecting value: line 1 column 2 (char 1)`
- Esto ocurre cuando la respuesta del LLM no es JSON v√°lido o est√° vac√≠a

## Conclusiones

1. **Low reasoning effort es el mejor**: 
   - ‚úÖ 100% de √©xito
   - ‚úÖ Mejor distribuci√≥n de posiciones (66.7% en P1)
   - ‚úÖ Sin problemas de tokens o parsing
   - ‚úÖ Posici√≥n promedio: 1.727

2. **Medium reasoning effort es bueno**: 
   - ‚úÖ 99.33% de √©xito (solo 1 caso rechazado)
   - ‚úÖ **Mejor posici√≥n promedio (1.664)** - incluso mejor que low
   - ‚úÖ Balance √≥ptimo entre reasoning y respuesta
   - ‚úÖ 65.8% en P1

3. **High reasoning effort es problem√°tico**: 
   - ‚ùå Solo 91.33% de √©xito (13 casos rechazados)
   - ‚ùå **Peor posici√≥n promedio (1.781)** incluso en casos exitosos
   - ‚ùå **Problema cr√≠tico #1**: Usa todos los 12,000 tokens de reasoning y no genera respuesta final
   - ‚ùå **Problema cr√≠tico #2**: Genera diagn√≥sticos **demasiado espec√≠ficos y complejos** que:
     - No coinciden exactamente con los GDX esperados (que suelen ser m√°s generales)
     - Requieren m√°s evaluaci√≥n sem√°ntica (menos coincidencias exactas por SNOMED/ICD10)
     - Cambian el orden de probabilidad debido a razonamiento excesivo sobre combinaciones complejas
   - ‚ùå Genera respuestas vac√≠as en 13 casos (8.67% del total)
   - ‚ùå Menos casos en P1 (64.2% vs 66.7% en low, 65.8% en medium)
   - ‚ùå M√°s casos en posiciones peores (P4-P10)
   - ‚ö†Ô∏è **No recomendado** - peor en todos los aspectos medibles

## Recomendaciones

1. **Usar `reasoning_effort: medium`** para obtener la mejor posici√≥n promedio (1.664) con 99.33% de √©xito
2. **Usar `reasoning_effort: low`** si se requiere 100% de √©xito absoluto (1.727 posici√≥n promedio)
3. **Evitar `reasoning_effort: high`** completamente:
   - ‚ùå **Peor posici√≥n promedio** (1.781) incluso en casos exitosos
   - ‚ùå **13 casos fallaron** (8.67% del total) debido a l√≠mite de tokens de reasoning
   - ‚ùå El modelo usa todos los 12,000 tokens de reasoning y no genera respuesta final
   - ‚ùå Menos casos en P1 y m√°s en posiciones peores
   - ‚ö†Ô∏è **No aporta ning√∫n beneficio** comparado con low/medium
4. **Si absolutamente se requiere `high` reasoning effort**:
   - Aumentar `max_tokens` significativamente (20,000-30,000)
   - Monitorear el uso de tokens de reasoning vs respuesta
   - Considerar implementar detecci√≥n de respuestas vac√≠as y reintentos autom√°ticos
   - **A√∫n as√≠, esperar peor posici√≥n promedio** que low/medium

## Comparaci√≥n con otros modelos

### gpt-5-mini (low)
- Success rate: 99.33% (149/150)
- Average position: 1.671
- Similar a gpt-5.2 medium

### grok-4-1-fast-reasoning (low)
- Success rate: ~similar (revisar summary espec√≠fico)
- Comparar con gpt-5.2 para ver diferencias

